{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'demoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4c7655a93a70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdemoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'demoji'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import demoji\n",
    "import urllib.request as req\n",
    "import re\n",
    "import webbrowser\n",
    "from pytube import YouTube\n",
    "from matplotlib import pyplot as plt\n",
    "from langdetect import detect\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Activating AutoCompleter in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_VIDEO_URL = 'https://www.youtube.com/watch?v={youtube_id}'\n",
    "YOUTUBE_COMMENTS_AJAX_URL = 'https://www.youtube.com/comment_service_ajax'\n",
    "USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'\n",
    "SORT_BY_POPULAR = 0\n",
    "SORT_BY_RECENT = 1\n",
    "URL = 'https://www.youtube.com/watch?v={}'\n",
    "FILENAME = r'json/{}.json'\n",
    "PIEPLOT = r'plots\\pie_{}_{}.png'\n",
    "BARPLOT = r'plots\\bar_{}_{}.png'\n",
    "SUBPLOT = r'plots\\sub_{}_{}.png'\n",
    "HTML = r'webpages\\{}.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API to retrieve youtube comments\n",
    "### Do not Edit the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value(html, key, num_chars=2, separator='\"'):\n",
    "    pos_begin = html.find(key) + len(key) + num_chars\n",
    "    pos_end = html.find(separator, pos_begin)\n",
    "    return html[pos_begin: pos_end]\n",
    "\n",
    "def ajax_request(session, url, params=None, data=None, headers=None, retries=5, sleep=20):\n",
    "    for _ in range(retries):\n",
    "        response = session.post(url, params=params, data=data, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        if response.status_code in [403, 413]:\n",
    "            return {}\n",
    "        else:\n",
    "            time.sleep(sleep)\n",
    "\n",
    "def download_comments(youtube_id, sort_by=SORT_BY_RECENT, sleep=.1):\n",
    "    session = requests.Session()\n",
    "    session.headers['User-Agent'] = USER_AGENT\n",
    "    response = session.get(YOUTUBE_VIDEO_URL.format(youtube_id=youtube_id))\n",
    "\n",
    "    if 'uxe=' in response.request.url:\n",
    "        session.cookies.set('CONSENT', 'YES+cb', domain='.youtube.com')\n",
    "        response = session.get(YOUTUBE_VIDEO_URL.format(youtube_id=youtube_id))\n",
    "    \n",
    "    ncd = None\n",
    "    html = response.text\n",
    "    session_token = find_value(html, 'XSRF_TOKEN', 3)\n",
    "    session_token = session_token.encode('ascii').decode('unicode-escape')\n",
    "    \n",
    "    data = json.loads(find_value(html, 'var ytInitialData = ', 0, '};') + '}')\n",
    "    for renderer in search_dict(data, 'itemSectionRenderer'):\n",
    "        ncd = next(search_dict(renderer, 'nextContinuationData'), None)\n",
    "        if ncd: break\n",
    "\n",
    "    if not ncd:\n",
    "        # Comments disabled?\n",
    "        return\n",
    "\n",
    "    needs_sorting = sort_by != SORT_BY_POPULAR\n",
    "    continuations = [(ncd['continuation'], ncd['clickTrackingParams'], 'action_get_comments')]\n",
    "    while continuations:\n",
    "        continuation, itct, action = continuations.pop()\n",
    "        response = ajax_request(session, YOUTUBE_COMMENTS_AJAX_URL,\n",
    "                                params={action: 1,\n",
    "                                        'pbj': 1,\n",
    "                                        'ctoken': continuation,\n",
    "                                        'continuation': continuation,\n",
    "                                        'itct': itct},\n",
    "                                data={'session_token': session_token},\n",
    "                                headers={'X-YouTube-Client-Name': '1',\n",
    "                                         'X-YouTube-Client-Version': '2.20201202.06.01'})\n",
    "\n",
    "        if not response:\n",
    "            break\n",
    "        if list(search_dict(response, 'externalErrorMessage')):\n",
    "            raise RuntimeError('Error returned from server: ' + next(search_dict(response, 'externalErrorMessage')))\n",
    "\n",
    "        if needs_sorting:\n",
    "            sort_menu = next(search_dict(response, 'sortFilterSubMenuRenderer'), {}).get('subMenuItems', [])\n",
    "            if sort_by < len(sort_menu):\n",
    "                ncd = sort_menu[sort_by]['continuation']['reloadContinuationData']\n",
    "                continuations = [(ncd['continuation'], ncd['clickTrackingParams'], 'action_get_comments')]\n",
    "                needs_sorting = False\n",
    "                continue\n",
    "            raise RuntimeError('Failed to set sorting')\n",
    "\n",
    "        if action == 'action_get_comments':\n",
    "            section = next(search_dict(response, 'itemSectionContinuation'), {})\n",
    "            for continuation in section.get('continuations', []):\n",
    "                ncd = continuation['nextContinuationData']\n",
    "                continuations.append((ncd['continuation'], ncd['clickTrackingParams'], 'action_get_comments'))\n",
    "            for item in section.get('contents', []):\n",
    "                continuations.extend([(ncd['continuation'], ncd['clickTrackingParams'], 'action_get_comment_replies')\n",
    "                                      for ncd in search_dict(item, 'nextContinuationData')])\n",
    "\n",
    "        elif action == 'action_get_comment_replies':\n",
    "            continuations.extend([(ncd['continuation'], ncd['clickTrackingParams'], 'action_get_comment_replies')\n",
    "                                  for ncd in search_dict(response, 'nextContinuationData')])\n",
    "\n",
    "        for comment in search_dict(response, 'commentRenderer'):\n",
    "            yield {'cid': comment['commentId'],\n",
    "                   'text': ''.join([c['text'] for c in comment['contentText'].get('runs', [])]),\n",
    "                   'time': comment['publishedTimeText']['runs'][0]['text'],\n",
    "                   'author': comment.get('authorText', {}).get('simpleText', ''),\n",
    "                   'channel': comment['authorEndpoint']['browseEndpoint']['browseId'],\n",
    "                   'votes': comment.get('voteCount', {}).get('simpleText', '0'),\n",
    "                   'photo': comment['authorThumbnail']['thumbnails'][-1]['url'],\n",
    "                   'heart': next(search_dict(comment, 'isHearted'), False)}\n",
    "        time.sleep(sleep)\n",
    "\n",
    "def search_dict(partial, search_key):\n",
    "    stack = [partial]\n",
    "    while stack:\n",
    "        current_item = stack.pop()\n",
    "        if isinstance(current_item, dict):\n",
    "            for key, value in current_item.items():\n",
    "                if key == search_key:\n",
    "                    yield value\n",
    "                else:\n",
    "                    stack.append(value)\n",
    "        elif isinstance(current_item, list):\n",
    "            for value in current_item:\n",
    "                stack.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Downloading emoji codes and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadEmojiCodes():\n",
    "    demoji.download_codes()\n",
    "def downloadNLTKStopWords():\n",
    "    import nltk\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to get Video Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoInfo(video_id):\n",
    "    url = YOUTUBE_VIDEO_URL.format(youtube_id = video_id)\n",
    "    data = YouTube(url)\n",
    "    title = data.title\n",
    "    views = data.views\n",
    "    rating = data.rating\n",
    "    thumbnail_url = data.thumbnail_url\n",
    "    return url, title, thumbnail_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to open link in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openInBrowser(link):\n",
    "    webbrowser.open_new_tab(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Download Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadComments(youtube_id = None, limit=10, sort=1):\n",
    "    if not youtube_id :\n",
    "        youtube_id = input(\"Enter Youtube Video ID :\").strip()\n",
    "        limit = int(input(\"Enter number of comments to be retrieved :\"))\n",
    "        sort = int(input(\"Enter sorting order \\n(download popular (0) ; recent comments (1). Defaults to 1) \\t :\"))\n",
    "    comments = []\n",
    "    try:\n",
    "        if not youtube_id:\n",
    "            raise ValueError('You need to specify a Youtube ID')\n",
    "        print('Downloading Youtube comments for video :', youtube_id)\n",
    "        count = 0\n",
    "        i = 1\n",
    "        g_comments = download_comments(youtube_id, sort)\n",
    "        print('_' * 100)\n",
    "        for comment in g_comments:\n",
    "            count += 1\n",
    "            comments.append(comment)\n",
    "            if int(count * 100 / limit) == i: print('*', end=''); i += 1\n",
    "            if count >= limit: break\n",
    "        if comments: print('\\nDownloaded')\n",
    "        else: print('\\nNo Comments Found')\n",
    "    except Exception as e:\n",
    "        print('\\nError :', str(e))\n",
    "    print('{} Comments Downloaded'.format(len(comments)))\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to get Views, Likes, Dislikes count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVLDCount(video_id):\n",
    "    html = str(req.urlopen(URL.format(video_id)).read())\n",
    "    res = [*map(lambda x:x.split(), list(zip(*re.findall(r'((\\d+(,\\d+)*) (dislikes|likes|views|comments))', html)))[0])]\n",
    "    Views = Likes = Dislikes = 0\n",
    "    for i in res:\n",
    "        n = int(''.join(i[0].split(',')))\n",
    "        if 'views' in i and n:\n",
    "            if not Views: Views = n\n",
    "        elif 'likes' in i and n:\n",
    "            if not Likes: Likes = n\n",
    "        elif 'dislikes' in i and n:\n",
    "            if not Dislikes: Dislikes = n\n",
    "    return Views, Likes, Dislikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Download the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRequirements(video_id, limit=1000, sort=1):\n",
    "    \"\"\"\n",
    "        This Function takes the following inputs\n",
    "            video_id : (str) id of the video\n",
    "            limit(optional) : (int) number of comments to be downloaded\n",
    "            sort_order(optional) : (int) 0 or 1; defaults to zero\n",
    "        Returns\n",
    "            comments : list of dictionaries\n",
    "            views : no_of_views\n",
    "            likes : no_of_likes\n",
    "            dislikes : no_of_dislikes\n",
    "    \"\"\"\n",
    "    FILE_NAME = FILENAME.format(video_id)\n",
    "    try:\n",
    "        with open(FILE_NAME) as J: comments = json.load(J)\n",
    "        print('Dataset Exists. Opening...')\n",
    "        print('Opened')\n",
    "        print('{} Comments Found'.format(len(comments)))\n",
    "    except:\n",
    "        print('Dataset Not Found. Downloading...')\n",
    "        comments = downloadComments(video_id, limit)\n",
    "        try:\n",
    "            with open(FILE_NAME, 'w') as J: json.dump(comments, J)\n",
    "        except:\n",
    "            print('Unable to save the Dataset')\n",
    "    views, likes, dislikes = getVLDCount(video_id)\n",
    "    return comments, views, likes, dislikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to detect language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(x):\n",
    "    lang = None\n",
    "    if x:\n",
    "        try: lang = detect(x)\n",
    "        except: pass\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to process the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(comments, likes=1, dislikes=0):\n",
    "    print('Processing DataFrame...')\n",
    "    df_comments = pd.DataFrame(comments)\n",
    "    df_emoji_data = pd.read_csv('Emoji_Sentiment_Data.csv')[['Emoji', 'Negative', 'Neutral', 'Positive']]\n",
    "    df_emoji_data['emoji_score'] = df_emoji_data['Positive'] - df_emoji_data['Negative'] + (60 / df_emoji_data['Neutral'] * 100) - (40 / df_emoji_data['Neutral'] * 100)\n",
    "    emoji_scores = df_emoji_data.set_index('Emoji')['emoji_score'].to_dict()\n",
    "    pattern = r\"[^\\w']+\" # pattern = r'[\\W_]+'\n",
    "    stop_words = list(get_stop_words('en'))\n",
    "    try:\n",
    "        nltk_words = list(stopwords.words('english'))\n",
    "    except:\n",
    "        downloadNLTKStopWords()\n",
    "        nltk_words = list(stopwords.words('english'))\n",
    "    stop_words.extend(nltk_words)\n",
    "    stop_words = nltk_words\n",
    "    negative_words_data = None\n",
    "    with open('negative_words.txt','r') as f: negative_words_data = f.read().split()\n",
    "    try:\n",
    "        df_comments['emojies'] = df_comments['text'].apply(lambda x : demoji.findall_list(x, desc=False))\n",
    "    except:\n",
    "        downloadEmojiCodes()\n",
    "        df_comments['emojies'] = df_comments['text'].apply(lambda x : demoji.findall_list(x, desc=False))\n",
    "    df_comments['comments'] = df_comments[\"text\"].apply(lambda x : demoji.replace(x,\"\"))\n",
    "    df_comments['votes'] = df_comments['votes'].apply(lambda x : float(x[:-1]) * 1000 if x[-1].lower() == 'k' else float(x))\n",
    "    df_comments['emoji_scores'] = df_comments['emojies'].apply(lambda x : sum([emoji_scores[i] if i and i in emoji_scores and emoji_scores[i] else 0 for i in x]))\n",
    "    df_comments['emoji_scores'] = df_comments['emoji_scores'].fillna(0)\n",
    "    df_comments['language'] = df_comments['comments'].apply(detect_lang)\n",
    "    df_comments = df_comments[df_comments['language'] == 'en']\n",
    "    df_comments['comments'] = df_comments['comments'].apply(lambda x : re.sub(pattern,\" \",x))\n",
    "    df_comments['comments_stopword_less'] = df_comments['comments'].apply(lambda x : ' '.join([i for i in x.split() if i not in stop_words]))\n",
    "    df_comments['words'] = df_comments['comments_stopword_less'].apply(lambda x : x.split())\n",
    "    df_comments['negative_words'] = df_comments['words'].apply(lambda x : [i for i in x if i in negative_words_data])\n",
    "    df_comments['word_scores'] = 1 - df_comments['negative_words'].str.len() / df_comments['words'].str.len()\n",
    "    df_comments['word_scores'] = df_comments['word_scores'].fillna(0)\n",
    "    word_per  = (df_comments['word_scores'].sum() / len(df_comments['word_scores']))\n",
    "    likes_per = ((likes) / (likes + dislikes))\n",
    "    pve = df_comments[df_comments['emoji_scores'] > 0]['emoji_scores'].sum()\n",
    "    nve = -df_comments[df_comments['emoji_scores'] < 0]['emoji_scores'].sum()\n",
    "    emoji_per = (pve) / (pve + nve)\n",
    "    df_comments['neg_comment'] = df_comments['negative_words'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "    neg_comments_count = df_comments['neg_comment'].sum()\n",
    "    pos_comments_count = len(df_comments['neg_comment']) - neg_comments_count\n",
    "    result = (likes_per * 0.70) + (emoji_per * 0.20) + (word_per * 0.10)\n",
    "    return df_comments, likes_per, emoji_per, word_per, result, pos_comments_count, neg_comments_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Pieplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piePlot(values, title='Chart', explode=(0.2, 0), colors=['green', 'red'], labels=['positive', 'negative'],\\\n",
    "            shadow=True, startangle=0, autopct='%1.2f%%', save=0):\n",
    "    plt.pie(values, labels=labels, autopct=autopct, explode=explode, shadow=shadow, colors=colors)\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    if save:\n",
    "        f_name = PIEPLOT.format(video_id, ''.join(title.split()))\n",
    "        plt.savefig(f_name)\n",
    "        print('{} Saved'.format(f_name))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for BarPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barPlot(values, title='Chart', labels=['positive', 'negative'], colors=['green', 'red'],\\\n",
    "            xlabel='Positive - Negative', ylabel='Positive - Negative Count', save=0):\n",
    "    plt.bar(labels, values, color=colors)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if save:\n",
    "        f_name = BARPLOT.format(video_id, ''.join(title.split()))\n",
    "        plt.savefig(f_name)\n",
    "        print('{} Saved'.format(f_name))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for SubPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subPlot(value1, value2, value3, value4, title='Chart', plotlabels=['Likes', 'Emojies', 'Comments', 'Result'], explode=(0.2, 0),\\\n",
    "            colors=['green', 'red'], labels=['positive', 'negative'], shadow=True, startangle=0, autopct='%1.2f%%', save=0):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axs[0, 0].pie(value1, labels=labels, autopct=autopct, explode=explode, shadow=shadow, colors=colors)\n",
    "    axs[0, 0].set_title(plotlabels[0])\n",
    "    axs[0, 1].pie(value2, labels=labels, autopct=autopct, explode=explode, shadow=shadow, colors=colors)\n",
    "    axs[0, 1].set_title(plotlabels[1])\n",
    "    axs[1, 0].pie(value3, labels=labels, autopct=autopct, explode=explode, shadow=shadow, colors=colors)\n",
    "    axs[1, 0].set_title(plotlabels[2])\n",
    "    axs[1, 1].pie(value4, labels=labels, autopct=autopct, explode=explode, shadow=shadow, colors=colors)\n",
    "    axs[1, 1].set_title(plotlabels[3])\n",
    "    fig.legend()\n",
    "    # for ax in axs.flat: ax.set(xlabel='x-label', ylabel='y-label')\n",
    "    for ax in axs.flat: ax.label_outer()\n",
    "    if save:\n",
    "        f_name = SUBPLOT.format(video_id, ''.join(title.split()))\n",
    "        plt.savefig(f_name)\n",
    "        print('{} Saved'.format(f_name))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function All in One (Code for all in one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doAll(video_id, count=1000, sort=1, save=0):\n",
    "    comments, views, likes, dislikes = getRequirements(video_id, count, sort)\n",
    "    print(\"Views : {} ; Likes : {} ; Dislikes : {}\".format(views, likes, dislikes))\n",
    "    df_comments, likes_per, emoji_per, word_per, result, pos_comments_count, neg_comments_count = process(comments, likes, dislikes)\n",
    "    values_likes = [likes_per, 1 - likes_per]\n",
    "    values_emojies = [emoji_per, 1 - emoji_per]\n",
    "    values_words = [word_per, 1 - word_per]\n",
    "    values_res = [result, 1 - result]\n",
    "    values_neg = [pos_comments_count, neg_comments_count]\n",
    "    piePlot(values_likes, \"Likes Chart\", save=save)\n",
    "    piePlot(values_emojies, \"Emojies Chart\", save=save)\n",
    "    piePlot(values_words, \"Comments Chart\", save=save)\n",
    "    piePlot(values_res, \"Result Chart\", save=save)\n",
    "    barPlot(values_neg, 'Positive-Negative Comments Chart', save=save)\n",
    "    subPlot(values_likes, values_emojies, values_words, values_res, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in One Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Comments of given youtube video ID, getting Views, Likes, Dislikes Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"video_id\" not in globals() : video_id = input(\"Enter Video ID :\").strip()\n",
    "doAll(video_id, count=5000, save=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url, title, thumb = getVideoInfo(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Template.txt') as T: Temp = T.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_values = {\"video_id\":video_id,\n",
    "               \"video_title\":title,\n",
    "               \"video_id\":video_id,\n",
    "               \"chart1_title\":'Likes Chart',\n",
    "               \"chart2_title\":'Emojies Chart',\n",
    "               \"chart3_title\":'Comments Chart',\n",
    "               \"chart4_title\":'Result Chart',\n",
    "               \"chart1-image\":PIEPLOT.format(video_id, 'LikesChart'),\n",
    "               \"chart2-image\":PIEPLOT.format(video_id, 'EmojiesChart'),\n",
    "               \"chart3-image\":PIEPLOT.format(video_id, 'CommentsChart'),\n",
    "               \"chart4-image\":PIEPLOT.format(video_id, 'ResultChart')}\n",
    "html = Temp.format(**html_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HTML.format(video_id), 'w') as H:\n",
    "    H.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openInBrowser(HTML.format(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
